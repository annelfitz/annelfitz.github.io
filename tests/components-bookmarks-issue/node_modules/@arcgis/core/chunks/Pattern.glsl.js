/*
All material copyright ESRI, All Rights Reserved, unless otherwise specified.
See https://js.arcgis.com/4.30/esri/copyright.txt for details.
*/
import{addNearFar as e,addLinearDepth as o}from"../views/3d/webgl-engine/core/shaderLibrary/ForwardLinearDepth.glsl.js";import{ShaderOutput as r}from"../views/3d/webgl-engine/core/shaderLibrary/ShaderOutput.js";import{SliceDraw as t}from"../views/3d/webgl-engine/core/shaderLibrary/Slice.glsl.js";import{Transform as a}from"../views/3d/webgl-engine/core/shaderLibrary/Transform.glsl.js";import{ObjectAndLayerIdColor as i}from"../views/3d/webgl-engine/core/shaderLibrary/attributes/ObjectAndLayerIdColor.glsl.js";import{VertexColor as l}from"../views/3d/webgl-engine/core/shaderLibrary/attributes/VertexColor.glsl.js";import{OutputDepth as n}from"../views/3d/webgl-engine/core/shaderLibrary/output/OutputDepth.glsl.js";import{OutputHighlight as c}from"../views/3d/webgl-engine/core/shaderLibrary/output/OutputHighlight.glsl.js";import{multipassTerrainTest as d}from"../views/3d/webgl-engine/core/shaderLibrary/shading/MultipassTerrainTest.glsl.js";import{VisualVariables as s}from"../views/3d/webgl-engine/core/shaderLibrary/shading/VisualVariables.glsl.js";import{symbolAlphaCutoff as p}from"../views/3d/webgl-engine/core/shaderLibrary/util/AlphaCutoff.js";import{ColorConversion as g}from"../views/3d/webgl-engine/core/shaderLibrary/util/ColorConversion.glsl.js";import{addProjViewLocalOrigin as u,addCameraPosition as v}from"../views/3d/webgl-engine/core/shaderLibrary/util/View.glsl.js";import{Float4PassUniform as m}from"../views/3d/webgl-engine/core/shaderModules/Float4PassUniform.js";import{FloatPassUniform as f}from"../views/3d/webgl-engine/core/shaderModules/FloatPassUniform.js";import{glsl as h}from"../views/3d/webgl-engine/core/shaderModules/interfaces.js";import{ShaderBuilder as w}from"../views/3d/webgl-engine/core/shaderModules/ShaderBuilder.js";import{TransparencyPassType as b}from"../views/3d/webgl-engine/lib/TransparencyPassType.js";import{VertexAttribute as y}from"../views/3d/webgl-engine/lib/VertexAttribute.js";import{Style as j}from"../views/3d/webgl-engine/materials/PatternStyle.js";const S=.70710678118,C=S,x=.08715574274;function T(T){const R=new w,$=T.multipassEnabled&&(T.output===r.Color||T.output===r.Alpha),{vertex:D,fragment:L,attributes:V,varyings:A}=R;u(D,T),R.include(a,T),R.include(l,T),R.include(s,T),R.include(i,T),T.draped?D.uniforms.add(new f("worldToScreenRatio",((e,o)=>1/o.screenToPCSRatio))):V.add(y.BOUNDINGRECT,"mat3"),V.add(y.POSITION,"vec3"),V.add(y.UVMAPSPACE,"vec4"),T.vvColor&&V.add(y.COLORFEATUREATTRIBUTE,"float"),A.add("vColor","vec4"),A.add("vpos","vec3"),A.add("vuv","vec2"),$&&A.add("depth","float"),D.uniforms.add(new m("uColor",(e=>e.color)));const O=T.style===j.ForwardDiagonal||T.style===j.BackwardDiagonal||T.style===j.DiagonalCross;O&&D.code.add(h`
      const mat2 rotate45 = mat2(${h.float(S)}, ${h.float(-C)},
                                 ${h.float(C)}, ${h.float(S)});
    `),T.draped||(v(D,T),D.uniforms.add(new f("worldToScreenPerDistanceRatio",((e,o)=>1/o.camera.perScreenPixelRatio))),D.code.add(h`vec3 projectPointToLineSegment(vec3 center, vec3 halfVector, vec3 point) {
float projectedLength = dot(halfVector, point - center) / dot(halfVector, halfVector);
return center + halfVector * clamp(projectedLength, -1.0, 1.0);
}`),D.code.add(h`vec3 intersectRayPlane(vec3 rayDir, vec3 rayOrigin, vec3 planeNormal, vec3 planePoint) {
float d = dot(planeNormal, planePoint);
float t = (d - dot(planeNormal, rayOrigin)) / dot(planeNormal, rayDir);
return rayOrigin + t * rayDir;
}`),D.code.add(h`
      float boundingRectDistanceToCamera() {
        vec3 center = vec3(boundingRect[0][0], boundingRect[0][1], boundingRect[0][2]);
        vec3 halfU = vec3(boundingRect[1][0], boundingRect[1][1], boundingRect[1][2]);
        vec3 halfV = vec3(boundingRect[2][0], boundingRect[2][1], boundingRect[2][2]);
        vec3 n = normalize(cross(halfU, halfV));

        vec3 viewDir = - vec3(view[0][2], view[1][2], view[2][2]);

        float viewAngle = dot(viewDir, n);
        float minViewAngle = ${h.float(x)};

        if (abs(viewAngle) < minViewAngle) {
          // view direction is (almost) parallel to plane -> clamp it to min angle
          float normalComponent = sign(viewAngle) * minViewAngle - viewAngle;
          viewDir = normalize(viewDir + normalComponent * n);
        }

        // intersect view direction with infinite plane that contains bounding rect
        vec3 planeProjected = intersectRayPlane(viewDir, cameraPosition, n, center);

        // clip to bounds by projecting to u and v line segments individually
        vec3 uProjected = projectPointToLineSegment(center, halfU, planeProjected);
        vec3 vProjected = projectPointToLineSegment(center, halfV, planeProjected);

        // use to calculate the closest point to camera on bounding rect
        vec3 closestPoint = uProjected + vProjected - center;

        return length(closestPoint - cameraPosition);
      }
    `)),D.code.add(h`
    vec2 scaledUV() {
      vec2 uv = uvMapSpace.xy ${O?" * rotate45":""};
      vec2 uvCellOrigin = uvMapSpace.zw ${O?" * rotate45":""};

      ${T.draped?"":h`
            float distanceToCamera = boundingRectDistanceToCamera();
            float worldToScreenRatio = worldToScreenPerDistanceRatio / distanceToCamera;
          `}

      // Logarithmically discretize ratio to avoid jittering
      float step = 0.1;
      float discreteWorldToScreenRatio = log(worldToScreenRatio);
      discreteWorldToScreenRatio = ceil(discreteWorldToScreenRatio / step) * step;
      discreteWorldToScreenRatio = exp(discreteWorldToScreenRatio);

      vec2 uvOffset = mod(uvCellOrigin * discreteWorldToScreenRatio, ${h.float(T.patternSpacing)});
      return uvOffset + (uv * discreteWorldToScreenRatio);
    }
  `);const z=T.output===r.LinearDepth;return z&&(R.include(n,T),e(R),o(R)),D.code.add(h`
    void main(void) {
      vuv = scaledUV();
      vpos = position;
      ${$?"depth = (view * vec4(vpos, 1.0)).z;":""}
      forwardNormalizedVertexColor();
      forwardObjectAndLayerIdColor();
      ${T.hasVertexColors?"vColor *= uColor;":T.vvColor?"vColor = uColor * interpolateVVColor(colorFeatureAttribute);":"vColor = uColor;"}
      gl_Position = ${z?h`transformPositionWithDepth(proj, view, vpos, nearFar, linearDepth);`:h`transformPosition(proj, view, vpos);`}
    }
  `),R.include(t,T),L.include(g),T.draped&&L.uniforms.add(new f("texelSize",((e,o)=>1/o.camera.pixelRatio))),T.output===r.Highlight&&R.include(c,T),$&&R.include(d,T),T.output!==r.Highlight&&(L.code.add(h`
      const float lineWidth = ${h.float(T.lineWidth)};
      const float spacing = ${h.float(T.patternSpacing)};
      const float spacingINV = ${h.float(1/T.patternSpacing)};

      float coverage(float p, float txlSize) {
        p = mod(p, spacing);

        float halfTxlSize = txlSize / 2.0;

        float start = p - halfTxlSize;
        float end = p + halfTxlSize;

        float coverage = (ceil(end * spacingINV) - floor(start * spacingINV)) * lineWidth;
        coverage -= min(lineWidth, mod(start, spacing));
        coverage -= max(lineWidth - mod(end, spacing), 0.0);

        return coverage / txlSize;
      }
    `),T.draped||L.code.add(h`const int maxSamples = 5;
float sampleAA(float p) {
vec2 dxdy = abs(vec2(dFdx(p), dFdy(p)));
float fwidth = dxdy.x + dxdy.y;
ivec2 samples = 1 + ivec2(clamp(dxdy, 0.0, float(maxSamples - 1)));
vec2 invSamples = 1.0 / vec2(samples);
float accumulator = 0.0;
for (int j = 0; j < maxSamples; j++) {
if(j >= samples.y) {
break;
}
for (int i = 0; i < maxSamples; i++) {
if(i >= samples.x) {
break;
}
vec2 step = vec2(i,j) * invSamples - 0.5;
accumulator += coverage(p + step.x * dxdy.x + step.y * dxdy.y, fwidth);
}
}
accumulator /= float(samples.x * samples.y);
return accumulator;
}`)),L.code.add(h`
    void main() {
      discardBySlice(vpos);
      ${$?"terrainDepthTest(depth);":""}
      vec4 color = vColor;
      color = highlightSlice(color, vpos);

      ${T.output!==r.Highlight?h`color.a *= ${P(T)};`:""}

      ${T.output===r.ObjectAndLayerIdColor?h`color.a = 1.0;`:""}

      if (color.a < ${h.float(p)}) {
        discard;
      }

      ${T.output===r.Alpha?h`fragColor = vec4(color.a);`:""}

      ${T.output===r.Color?h`fragColor = color; ${T.transparencyPassType===b.Color?"fragColor = premultiplyAlpha(fragColor);":""}`:""}
      ${T.output===r.Highlight?h`outputHighlight();`:""}
      ${T.output===r.LinearDepth?h`outputDepth(linearDepth);`:""};
      ${T.output===r.ObjectAndLayerIdColor?h`outputObjectAndLayerIdColor();`:""}
    }
  `),R}function P(e){function o(o){return e.draped?h`coverage(vuv.${o}, texelSize)`:h`sampleAA(vuv.${o})`}switch(e.style){case j.ForwardDiagonal:case j.Horizontal:return o("y");case j.BackwardDiagonal:case j.Vertical:return o("x");case j.DiagonalCross:case j.Cross:return h`
        1.0 - (1.0 - ${o("x")}) * (1.0 - ${o("y")})
      `;default:return"0.0"}}const R=Object.freeze(Object.defineProperty({__proto__:null,build:T},Symbol.toStringTag,{value:"Module"}));export{R as P,T as b};
