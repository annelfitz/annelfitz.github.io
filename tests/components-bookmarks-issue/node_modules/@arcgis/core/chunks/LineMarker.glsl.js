/*
All material copyright ESRI, All Rights Reserved, unless otherwise specified.
See https://js.arcgis.com/4.30/esri/copyright.txt for details.
*/
import{markerTextureSize as e,markerSymbolSize as r,markerTipThicknessFactor as o}from"../views/3d/support/engineContent/marker.js";import{addLinearDepth as i,addCalculateLinearDepth as a}from"../views/3d/webgl-engine/core/shaderLibrary/ForwardLinearDepth.glsl.js";import{ShaderOutput as t}from"../views/3d/webgl-engine/core/shaderLibrary/ShaderOutput.js";import{SliceDraw as n}from"../views/3d/webgl-engine/core/shaderLibrary/Slice.glsl.js";import{RibbonVertexPosition as s}from"../views/3d/webgl-engine/core/shaderLibrary/attributes/RibbonVertexPosition.glsl.js";import{OutputDepth as l}from"../views/3d/webgl-engine/core/shaderLibrary/output/OutputDepth.glsl.js";import{MarkerSizing as c}from"../views/3d/webgl-engine/core/shaderLibrary/shading/MarkerSizing.glsl.js";import{multipassTerrainTest as d}from"../views/3d/webgl-engine/core/shaderLibrary/shading/MultipassTerrainTest.glsl.js";import{symbolAlphaCutoff as p}from"../views/3d/webgl-engine/core/shaderLibrary/util/AlphaCutoff.js";import{ColorConversion as v}from"../views/3d/webgl-engine/core/shaderLibrary/util/ColorConversion.glsl.js";import{RgbaFloatEncoding as m}from"../views/3d/webgl-engine/core/shaderLibrary/util/RgbaFloatEncoding.glsl.js";import{addProjViewLocalOrigin as f,addViewNormal as h,addPixelRatio as g}from"../views/3d/webgl-engine/core/shaderLibrary/util/View.glsl.js";import{Float2PassUniform as u}from"../views/3d/webgl-engine/core/shaderModules/Float2PassUniform.js";import{Float4PassUniform as w}from"../views/3d/webgl-engine/core/shaderModules/Float4PassUniform.js";import{FloatPassUniform as y}from"../views/3d/webgl-engine/core/shaderModules/FloatPassUniform.js";import{glsl as S}from"../views/3d/webgl-engine/core/shaderModules/interfaces.js";import{Matrix4PassUniform as b}from"../views/3d/webgl-engine/core/shaderModules/Matrix4PassUniform.js";import{ShaderBuilder as P}from"../views/3d/webgl-engine/core/shaderModules/ShaderBuilder.js";import{Texture2DPassUniform as x}from"../views/3d/webgl-engine/core/shaderModules/Texture2DPassUniform.js";import{TransparencyPassType as z}from"../views/3d/webgl-engine/lib/TransparencyPassType.js";import{VertexAttribute as L}from"../views/3d/webgl-engine/lib/VertexAttribute.js";import{LineMarkerSpace as j,LineMarkerAnchor as C}from"../views/3d/webgl-engine/shaders/LineMarkerTechniqueConfiguration.js";function M(M){const D=new P,k=M.multipassEnabled&&(M.output===t.Color||M.output===t.Alpha),N=M.space===j.World;D.include(s,M),D.include(c,M),M.output===t.LinearDepth&&D.include(l,M);const{vertex:T,fragment:A}=D;return A.include(m),f(T,M),D.attributes.add(L.POSITION,"vec3"),D.attributes.add(L.PREVPOSITION,"vec3"),D.attributes.add(L.UV0,"vec2"),D.varyings.add("vColor","vec4"),D.varyings.add("vpos","vec3"),D.varyings.add("vUV","vec2"),D.varyings.add("vSize","float"),i(D),k&&D.varyings.add("depth","float"),M.hasTip&&D.varyings.add("vLineWidth","float"),T.uniforms.add(new u("nearFar",((e,r)=>r.camera.nearFar)),new w("viewport",((e,r)=>r.camera.fullViewport))),T.code.add(S`vec4 projectAndScale(vec4 pos) {
vec4 posNdc = proj * pos;
posNdc.xy *= viewport.zw / posNdc.w;
return posNdc;
}`),T.code.add(S`void clip(vec4 pos, inout vec4 prev) {
float vnp = nearFar[0] * 0.99;
if (prev.z > -nearFar[0]) {
float interpolation = (-vnp - pos.z) / (prev.z - pos.z);
prev = mix(pos, prev, interpolation);
}
}`),N?(D.attributes.add(L.NORMAL,"vec3"),h(T),T.constants.add("tiltThreshold","float",.7),T.code.add(S`vec3 perpendicular(vec3 v) {
vec3 n = (viewNormal * vec4(normal.xyz, 1.0)).xyz;
vec3 n2 = cross(v, n);
vec3 forward = vec3(0.0, 0.0, 1.0);
float tiltDot = dot(forward, n);
return abs(tiltDot) < tiltThreshold ? n : n2;
}`)):T.code.add(S`vec2 perpendicular(vec2 v) {
return vec2(v.y, -v.x);
}`),T.code.add(S`
      #define vecN ${N?"vec3":"vec2"}

      vecN normalizedSegment(vecN pos, vecN prev) {
        vecN segment = pos - prev;
        float segmentLen = length(segment);

        // normalize or zero if too short
        return (segmentLen > 0.001) ? segment / segmentLen : ${N?"vec3(0.0, 0.0, 0.0)":"vec2(0.0, 0.0)"};
      }

      vecN displace(vecN pos, vecN prev, float displacementLen) {
        vecN segment = normalizedSegment(pos, prev);

        vecN displacementDirU = perpendicular(segment);
        vecN displacementDirV = segment;

        ${M.anchor===C.Tip?"pos -= 0.5 * displacementLen * displacementDirV;":""}

        return pos + displacementLen * (uv0.x * displacementDirU + uv0.y * displacementDirV);
      }
    `),M.space===j.Screen&&(T.uniforms.add(new b("inverseProjectionMatrix",((e,r)=>r.camera.inverseProjectionMatrix))),T.code.add(S`vec3 inverseProject(vec4 posScreen) {
posScreen.xy = (posScreen.xy / viewport.zw) * posScreen.w;
return (inverseProjectionMatrix * posScreen).xyz;
}`),T.code.add(S`bool rayIntersectPlane(vec3 rayDir, vec3 planeOrigin, vec3 planeNormal, out vec3 intersection) {
float cos = dot(rayDir, planeNormal);
float t = dot(planeOrigin, planeNormal) / cos;
intersection = t * rayDir;
return abs(cos) > 0.001 && t > 0.0;
}`),T.uniforms.add(new y("perScreenPixelRatio",((e,r)=>r.camera.perScreenPixelRatio))),T.code.add(S`
      vec4 toFront(vec4 displacedPosScreen, vec3 posLeft, vec3 posRight, vec3 prev, float lineWidth) {
        // Project displaced position back to camera space
        vec3 displacedPos = inverseProject(displacedPosScreen);

        // Calculate the plane that we want the marker to lie in. Note that this will always be an approximation since ribbon lines are generally
        // not planar and we do not know the actual position of the displaced prev vertices (they are offset in screen space, too).
        vec3 planeNormal = normalize(cross(posLeft - posRight, posLeft - prev));
        vec3 planeOrigin = posLeft;

        ${M.hasCap?"\n                if(prev.z > posLeft.z) {\n                  vec2 diff = posLeft.xy - posRight.xy;\n                  planeOrigin.xy += perpendicular(diff) / 2.0;\n                }\n              ":""};

        // Move the plane towards the camera by a margin dependent on the line width (approximated in world space). This tolerance corrects for the
        // non-planarity in most cases, but sharp joins can place the prev vertices at arbitrary positions so markers can still clip.
        float offset = lineWidth * perScreenPixelRatio;
        planeOrigin *= (1.0 - offset);

        // Intersect camera ray with the plane and make sure it is within clip space
        vec3 rayDir = normalize(displacedPos);
        vec3 intersection;
        if (rayIntersectPlane(rayDir, planeOrigin, planeNormal, intersection) && intersection.z < -nearFar[0] && intersection.z > -nearFar[1]) {
          return vec4(intersection.xyz, 1.0);
        }

        // Fallback: use depth of pos or prev, whichever is closer to the camera
        float minDepth = planeOrigin.z > prev.z ? length(planeOrigin) : length(prev);
        displacedPos *= minDepth / length(displacedPos);
        return vec4(displacedPos.xyz, 1.0);
      }
  `)),g(T),a(D),T.code.add(S`void main(void) {
if (uv0.y == 0.0) {
gl_Position = vec4(1e038, 1e038, 1e038, 1.0);
}
else {
float lineWidth = getLineWidth();
float screenMarkerSize = getScreenMarkerSize();
vec4 pos  = view * vec4(position, 1.0);
vec4 prev = view * vec4(prevPosition, 1.0);
clip(pos, prev);`),N?(M.hideOnShortSegments&&T.code.add(S`if (areWorldMarkersHidden(pos, prev)) {
gl_Position = vec4(1e038, 1e038, 1e038, 1.0);
return;
}`),T.code.add(S`pos.xyz = displace(pos.xyz, prev.xyz, getWorldMarkerSize(pos));
vec4 displacedPosScreen = projectAndScale(pos);`)):(T.code.add(S`vec4 posScreen = projectAndScale(pos);
vec4 prevScreen = projectAndScale(prev);
vec4 displacedPosScreen = posScreen;
displacedPosScreen.xy = displace(posScreen.xy, prevScreen.xy, screenMarkerSize);`),M.space===j.Screen&&T.code.add(S`vec2 displacementDirU = perpendicular(normalizedSegment(posScreen.xy, prevScreen.xy));
vec3 lineRight = inverseProject(posScreen + lineWidth * vec4(displacementDirU.xy, 0.0, 0.0));
vec3 lineLeft = pos.xyz + (pos.xyz - lineRight);
pos = toFront(displacedPosScreen, lineLeft, lineRight, prev.xyz, lineWidth);
displacedPosScreen = projectAndScale(pos);`)),T.code.add(S`
        ${k?"depth = pos.z;":""}
        linearDepth = calculateLinearDepth(nearFar,pos.z);

        // Convert back into NDC
        displacedPosScreen.xy = (displacedPosScreen.xy / viewport.zw) * displacedPosScreen.w;

        // Convert texture coordinate into [0,1]
        vUV = (uv0 + 1.0) / 2.0;

        ${N?"":"vUV *= displacedPosScreen.w;"}

        ${M.hasTip?"vLineWidth = lineWidth;":""}

        vSize = screenMarkerSize;
        vColor = getColor();

        // Use camera space for slicing
        vpos = pos.xyz;

        gl_Position = displacedPosScreen;
      }
    }
  `),k&&D.include(d,M),D.include(n,M),A.uniforms.add(new w("intrinsicColor",(e=>e.color)),new x("tex",(e=>e.markerTexture))),A.include(v),D.constants.add("texelSize","float",1/e),A.code.add(S`float markerAlpha(vec2 samplePos) {
samplePos += vec2(0.5, -0.5) * texelSize;
float sdf = rgba2float(texture(tex, samplePos)) - 0.5;
float distance = sdf * vSize;
distance -= 0.5;
return clamp(0.5 - distance, 0.0, 1.0);
}`),M.hasTip&&(D.constants.add("relativeMarkerSize","float",r/e),D.constants.add("relativeTipLineWidth","float",o),A.code.add(S`
    float tipAlpha(vec2 samplePos) {
      // Convert coordinates s.t. they are in pixels and relative to the tip of an arrow marker
      samplePos -= vec2(0.5, 0.5 + 0.5 * relativeMarkerSize);
      samplePos *= vSize;

      float halfMarkerSize = 0.5 * relativeMarkerSize * vSize;
      float halfTipLineWidth = 0.5 * max(1.0, relativeTipLineWidth * vLineWidth);

      ${N?"halfTipLineWidth *= fwidth(samplePos.y);":""}

      float distance = max(abs(samplePos.x) - halfMarkerSize, abs(samplePos.y) - halfTipLineWidth);
      return clamp(0.5 - distance, 0.0, 1.0);
    }
  `)),D.constants.add("symbolAlphaCutoff","float",p),A.code.add(S`
  void main() {
    discardBySlice(vpos);
    ${k?"terrainDepthTest(depth);":""}

    vec4 finalColor = intrinsicColor * vColor;

    ${N?"vec2 samplePos = vUV;":"vec2 samplePos = vUV * gl_FragCoord.w;"}

    ${M.hasTip?"finalColor.a *= max(markerAlpha(samplePos), tipAlpha(samplePos));":"finalColor.a *= markerAlpha(samplePos);"}

    ${M.output===t.ObjectAndLayerIdColor?S`finalColor.a = 1.0;`:""}

    if (finalColor.a < symbolAlphaCutoff) {
      discard;
    }

    ${M.output===t.Alpha?S`fragColor = vec4(finalColor.a);`:""}
    ${M.output===t.Color?S`fragColor = highlightSlice(finalColor, vpos);`:""}
    ${M.output===t.Color&&M.transparencyPassType===z.Color?"fragColor = premultiplyAlpha(fragColor);":""}
    ${M.output===t.Highlight?S`fragColor = vec4(1.0);`:""}
    ${M.output===t.LinearDepth?S`outputDepth(linearDepth);`:""}
  }
  `),D}const D=Object.freeze(Object.defineProperty({__proto__:null,build:M},Symbol.toStringTag,{value:"Module"}));export{D as L,M as b};
